{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD\n",
    "\n",
    "## Closures\n",
    "\n",
    "[RDD](https://spark.apache.org/docs/latest/rdd-programming-guide.html#understanding-closures-) may behave differently depending on whether execution is happening within the same JVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter value:  0\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "counter = 0\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# Wrong: Don't do this!!\n",
    "def increment_counter(x):\n",
    "    global counter\n",
    "    counter += x\n",
    "rdd.foreach(increment_counter)\n",
    "\n",
    "print(\"Counter value: \", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cluster modes, the variables within the closure sent to each executor are now copies and thus, when **counter** is referenced within the foreach function, it’s no longer the **counter** on the driver node. There is still a **counter** in the memory of the driver node but this is no longer visible to the executors! So use [*Accumulator*](https://spark.apache.org/docs/latest/rdd-programming-guide.html#accumulators) instead.\n",
    "\n",
    "Another common idiom is attempting to **print out** the elements of an RDD. However, in cluster mode, the output to **stdout** being called by the executors is now writing to the executor’s **stdout** instead, not the one on the driver, so **stdout** on the driver won’t show these! To print all elements on the driver, one can use the ```collect()``` method to first bring the RDD to the driver node. This can cause the driver to run out of memory, though, if you only need to print a few elements of the RDD, a safer approach is to use the ```take(): rdd.take(100)``` or ```sample()```\n",
    "\n",
    "## Run on Yarn\n",
    "\n",
    "<img src=\"images/spark_cluster.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "There are two deploy modes that can be used to launch Spark applications on YARN. In *cluster mode*, the Spark driver runs inside an application master process which is managed by YARN on the cluster, and the client can go away after initiating the application. In *client mode*, the driver runs in the client process, and the application master is only used for requesting resources from YARN.\n",
    "\n",
    "Unlike other cluster managers supported by Spark in which the master’s address is specified in the ```--master``` parameter, in YARN mode the **ResourceManager**’s address is picked up from the Hadoop configuration. Thus, the ```--master``` parameter is yarn.\n",
    "\n",
    "### Debugging\n",
    "In YARN terminology, executors and application masters run inside “containers”. YARN has two modes for handling container logs after an application has completed.\n",
    "\n",
    "- HDFS Shell / API\n",
    "- Spark Web UI under the Executors Tab\n",
    "\n",
    "### Web Interfaces\n",
    "Every SparkContext launches a web UI, by default on port 4040, that displays useful information about the application. This includes:\n",
    "\n",
    "- A list of scheduler stages and tasks\n",
    "- A summary of RDD sizes and memory usage\n",
    "- Environmental information.\n",
    "- Information about the running executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yarn\n",
    "\n",
    "<img src=\"images/yarn_architecture.gif\" style= \"width: 600px\"/>\n",
    "\n",
    "The fundamental idea of [YARN](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html) is to split up the functionalities of resource management and job scheduling/monitoring into separate daemons. The idea is to have a global **ResourceManager (RM)** and per-application **ApplicationMaster (AM)**.\n",
    "\n",
    "YARN supports the notion of **resource reservation** via the [ReservationSystem](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ReservationSystem.html), a component that allows users to specify a profile of resources over-time and temporal constraints (e.g., deadlines), and reserve resources to ensure the predictable execution of important jobs.The ReservationSystem tracks resources over-time, performs admission control for reservations, and dynamically instruct the underlying scheduler to ensure that the reservation is fullfilled.\n",
    "\n",
    "#### ResourceManager\n",
    "The **Scheduler** is responsible for allocating resources to the various running applications subject to familiar constraints of capacities, queues etc. The Scheduler is pure scheduler in the sense that it performs no monitoring or tracking of status for the application. Also, it offers no guarantees about restarting failed tasks either due to application failure or hardware failures. The Scheduler performs its scheduling function based on the resource requirements of the applications; it does so based on the abstract notion of a resource **Container** which incorporates elements such as **memory, cpu, disk, network etc**.\n",
    "\n",
    "The **Scheduler** has a pluggable policy which is responsible for partitioning the cluster resources among the various queues, applications etc. The current schedulers such as the CapacityScheduler and the FairScheduler would be some examples of plug-ins.\n",
    "\n",
    "#### ApplicationsManager\n",
    "The **ApplicationsManager** is responsible for accepting job-submissions, negotiating the first container for executing the application specific ApplicationMaster and provides the service for restarting the ApplicationMaster container on failure. The per-application ApplicationMaster has the responsibility of negotiating appropriate resource containers from the Scheduler, tracking their status and monitoring for progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "Such as: ```map(), filter(), groupBykey(), distinct(), sample()```\n",
    "\n",
    "## Actions\n",
    "\n",
    "Such as: ```reduce(), collect(), take(), foreach(), count()```\n",
    "\n",
    "## Persistence\n",
    "\n",
    "```cache()``` vs ```persist()```:\n",
    "- You can mark an RDD to be persisted using the ```persist()``` or ```cache()``` methods on it.\n",
    "- each persisted RDD can be stored using a different storage level\n",
    "- The ```cache()``` method is a shorthand for using the default storage level, which is StorageLevel.MEMORY_ONLY (store deserialized objects in memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Native BLAS/LAPACK for Spark\n",
    "\n",
    "Basically refer to [1. Use Native BLAS/LAPACK in Apache Spark](html/Use%20Native%20BLAS_LAPACK%20in%20Apache%20Spark.htm) and [2. SPARK ML offical introduce doc](https://spark.apache.org/docs/latest/ml-guide.html#dependencies)\n",
    "\n",
    "In above [1] 2.2 Step 2 more detail, we need to create a maven project and add some content to `pom.xml`. And Step 3 two params do need include the *jar* directory\n",
    "\n",
    "```xml\n",
    "<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n",
    "  <modelVersion>4.0.0</modelVersion>\n",
    "  <groupId>com.mycompany.app</groupId>\n",
    "  <artifactId>my-app</artifactId>\n",
    "  <packaging>jar</packaging>\n",
    "  <version>1.0-SNAPSHOT</version>\n",
    "  <name>my-app</name>\n",
    "  <url>http://maven.apache.org</url>\n",
    "  <build>\n",
    "    <plugins>\n",
    "      <!-- any other plugins -->\n",
    "      <plugin>\n",
    "        <artifactId>maven-assembly-plugin</artifactId>\n",
    "        <executions>\n",
    "          <execution>\n",
    "            <phase>package</phase>\n",
    "            <goals>\n",
    "              <goal>single</goal>\n",
    "            </goals>\n",
    "          </execution>\n",
    "        </executions>\n",
    "        <configuration>\n",
    "          <descriptorRefs>\n",
    "            <descriptorRef>jar-with-dependencies</descriptorRef>\n",
    "          </descriptorRefs>\n",
    "        </configuration>\n",
    "      </plugin>\n",
    "    </plugins>\n",
    "  </build>\n",
    "  <dependencies>\n",
    "    <dependency>\n",
    "      <groupId>junit</groupId>\n",
    "      <artifactId>junit</artifactId>\n",
    "      <version>3.8.1</version>\n",
    "      <scope>test</scope>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "      <groupId>com.github.fommil.netlib</groupId>\n",
    "      <artifactId>all</artifactId>\n",
    "      <version>1.1.2</version>\n",
    "      <type>pom</type>\n",
    "    </dependency>\n",
    "  </dependencies>\n",
    "</project>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
